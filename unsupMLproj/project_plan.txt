Fixed board plan for project:

1. Use ASReview to find papers reporting RIF resistance mutations
	- Search term used: ((rifampicin OR rifampin) AND (resistance OR resistant) AND (mutation OR polymorphism OR variant)).

		Initial manual screening with ASReview:
		Using active learning, the top-ranked 109 papers were manually screened, identifying 46 relevant ones.
		These labeled papers served as the initial training set for downstream machine learning.
		
		Model disagreement analysis (Round 1):
		Two language models were fine-tuned and applied:
		
		Sentence-BERT (all-MiniLM-L6-v2)
		
		SciBERT (allenai/scibert_scivocab_uncased)
		The models were used to predict labels on the remaining dataset. Among them, 1144 papers had disagreeing predictions (i.e., classified differently 		by the two models at threshold = 0.52).
		From these, 113 papers were manually annotated → 46 relevant.
		
		Model disagreement analysis (Round 2):
		A second set of 113 new disagreeing documents was selected and manually labeled → 25 relevant.
		
		Final labeled dataset:
		The three rounds of manual labeling resulted in 335 labeled papers, including both relevant and irrelevant examples.
		These were merged to form the final training set for model refinement.
		
		Model fine-tuning and cross-validation:
		The refined SciBERT model was trained on the full labeled dataset (334 usable records), and its performance was evaluated using Stratified 5-fold 		Cross-Validation, with the following averaged metrics:
		
		Best Threshold: 0.1420 ± 0.0546
		
		Precision: 0.4059 ± 0.0655
		
		Recall: 0.8283 ± 0.0702
		
		F1-score: 0.5385 ± 0.0434
		
		Final prediction on unlabeled data:
		The fine-tuned SciBERT model was then applied to the remaining 3139 previously unlabeled papers, identifying 142 predicted relevant entries for 		downstream analysis and data extraction.
2. Add data to our dataset of reported RIF resistance mutations
	2.1 Assess overlap: which papers do we already have
			found same paper (via DOI)-37
			different paper (via DOI)---170
			No doi paper---11
	
		
	2.2 For some (or all) papers that we haven't covered already, add new data
		data from paper after 2015 is added in docs:Newrifmutdata/ latestnewdata.xsxl
		aa pos——ecoli， aa——pos  is different, filled table by aligned targert species to ecoil .


3. Use unsupervised ML methods to identify clustering of mutations and species
	Planned methods:

		PCA for dimensionality reduction
		UMAP for nonlinear structure embedding
		HDBSCAN for identifying biologically meaningful mutation clusters
	Goals:
		Identify mutation patterns by species
		Explore cross-species “common resistance mutations”
 
4. Use supervised/PU-aware ML to predict which mutations should be observed in a species
       	Planned classifiers: Logistic Regression, Random Forest, Neural Networks
	PU treatment: Treat reported mutations as positives, all others as unlabeled; use Elkan–Noto correction (p_true = p_obs / c) and 	U-bagging to handle uncertain negatives.

	Targets:

		Predict novel rifampicin resistance mutations

		Flag likely false negatives in current catalogs

		Generalize to poorly studied species (e.g., M. abscessus, M. fortuitum)
	Evaluation & validation plan (PU-aware):

		PU-friendly internal validation (mask-then-recover): Randomly mask a fraction of known positives and test recovery among 		unlabeled; report Recall@K (K=1/5/10/20), MRR, nDCG, and threshold-based recall with conservative precision (lower bound).

		External generalization:

		Temporal split: train on papers ≤T, test on >T; measure forward validation (later-confirmed hits among Top-K, lead time).

		LOSO/LOTO: leave-one-species/clade out; evaluate Recall@K/MRR/nDCG on held-out taxa.

		Biological plausibility: Enrichment of predictions in RRDR/active-site/structural pockets; homologous-site concordance 			across species; optional conservation/ΔΔG support.

		Robustness & ablations: Negative controls (decoy mutations), permutation tests, feature ablations (e.g., remove effort / 		same-site alleles / similarity features), calibration (reliability curves), bootstrap CIs.

		Baselines & significance: Compare to frequency ranker, kNN label propagation, NMF/matrix completion, and effort-only 			ranker; report mean ± 95% CI and paired tests (e.g., Wilcoxon) on ranking metrics.